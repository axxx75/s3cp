# üîÑ Cloud Storage Sync

Applicazione web professionale per la sincronizzazione multi-cloud di storage utilizzando **rclone** come backend. Supporta interfaccia web intuitiva e API REST complete per automazione.

<div align="center">

![Version](https://img.shields.io/badge/version-1.0.0-blue)
![Python](https://img.shields.io/badge/python-3.6%2B-green)
![License](https://img.shields.io/badge/license-MIT-blue)
![Status](https://img.shields.io/badge/status-production-brightgreen)

**Provider Supportati:** GCS ‚Ä¢ ECS ‚Ä¢ S3 ‚Ä¢ 

</div>

---

## üìã Indice

- [‚ú® Features](#-features)
- [üìã Requisiti](#-requisiti)
- [‚ö° Quick Start](#-quick-start)
- [üìÅ Struttura Progetto](#-struttura-progetto)
- [üë• Manuale Utente](#-manuale-utente)
- [üíª Manuale Sviluppatore](#-manuale-sviluppatore)
- [üîå API Reference](#-api-reference)
- [üìö Use Cases](#-use-cases)
- [üîß Troubleshooting](#-troubleshooting)
- [ü§ù Contributi](#-contributi)

---

## ‚ú® Features

### üåê **Interfaccia Web Moderna**
- **Design responsive** ottimizzato per desktop e mobile
- **Real-time monitoring** dei job di sincronizzazione
- **Gestione credenziali** sicura per diversi provider
- **Upload file JSON** drag-and-drop per Service Account
- **Console output** live con streaming log

### üîó **Multi-Provider Support**
- **Google Cloud Storage (GCS)**: HMAC + Service Account
- **Elastic Cloud Storage (ECS)**: S3-compatible
- **Amazon S3**: Standard e compatibili
- **MinIO**: Self-hosted storage
- **Cloudflare R2**: Edge storage

### üîß **Autenticazione Flessibile**
- **HMAC**: Access Key + Secret Key
- **Service Account**: File JSON o testo (GCS)
- **Project Number**: Supporto automatico per GCS
- **Environment isolation**: Credenziali sicure per job

### üöÄ **API REST Complete**
- **Job management**: Creazione, monitoring, listing
- **Server-Sent Events**: Stream real-time dei log
- **JSON API**: Integrabile in workflow esistenti
- **Automazione**: Supporto completo per scripting

---

## üìã Requisiti

### **Sistema**
- **Python**: 3.6 o superiore
- **rclone**: 1.50+ installato e configurabile
- **OS**: Linux, macOS, Windows (WSL supportato)

### **Python Dependencies**
```bash
flask>=2.0.0
python-dotenv>=0.19.0
flask-talisman
```

---

## ‚ö° Quick Start

### **1Ô∏è‚É£ Clona e Installa**
```bash
cd /opt
git clone https://github.com/axxx75/s3cp.git
cd s3cp
python3 -m venv venv
source venv/bin/activate
pip install flask python-dotenv gunicorn flask-talisman
```

### **2Ô∏è‚É£ Configura rclone**
```bash
# Installa rclone se non presente
curl https://rclone.org/install.sh | bash

# Verifica installazione
rclone version
```

### **3Ô∏è‚É£ Avvia l'applicazione (installazione come service)**
```bash
cp s3cp-webapp.service /etc/systemd/system/
systemctl daemon-reload
systemctl enable s3cp-webapp
systemctl start s3cp-webapp

# Se vuoi il server in HTTPS scommenta le 2 righe nel file gunicorn.conf.py
Documentati bene su come farlo seriamente, eventualmente con una CA. Al volo puoi fare come segue, crea i file server.crt e server.key nella dir dell'app
 openssl req -x509 -newkey rsa:4096 -nodes -keyout app/server.key -out app/server.crt -days 365 -subj "/CN=localhost"

# Verifica start
journalctl -u s3cp-webapp.service -f
```

### **4Ô∏è‚É£ Accedi all'interfaccia**
```
üåê http://localhost:8080
```

---

## üìÅ Struttura Progetto

```
s3cputo/
‚îú‚îÄ‚îÄ üìÑ start.sh                  # üîß Script per start application
‚îú‚îÄ‚îÄ üìÑ gunicorn.conf.py          # üîß File conf server gunicorn
‚îú‚îÄ‚îÄ üìÑ s3cp-webapp.service    # üîß Script for service configuration
‚îú‚îÄ‚îÄ üìÑ README.md                 # üìñ Questo file
‚îú‚îÄ‚îÄ üìÅ app/                      # üìÅ Folder Application
‚îÇ   ‚îî‚îÄ‚îÄ üìÅ static/               # üìÅ Folder static content
‚îÇ       ‚îî‚îÄ‚îÄ üìÑ custom.css        # üé® Styling dell'interfaccia web
‚îÇ   ‚îî‚îÄ‚îÄ üìÅ templates/            # üìÅ Folder template html
‚îÇ       ‚îî‚îÄ‚îÄ üìÑ index.html        # üåê Single-page application UI
|   ‚îî‚îÄ‚îÄ üìÑ app.py                # üîß Main Flask application
|   ‚îî‚îÄ‚îÄ üìÑ config.py             # ‚öôÔ∏è Provider configurations & flags

```

### **üìÑ File Principali**

| File | Scopo | Descrizione |
|------|-------|-------------|
| `app.py` | üîß **Backend** | Flask app, API endpoints, job management |
| `config.py` | ‚öôÔ∏è **Configurazione** | Provider configs, rclone flags, paths |
| `index.html` | üåê **Frontend** | SPA con JavaScript per UI interattiva |
| `custom.css` | üé® **Styling** | Design moderno con glassmorphism |

---

## üë• Manuale Utente

### **üåê Interfaccia Web**

#### **1Ô∏è‚É£ Configurazione Source (Sorgente)**
1. **Seleziona Provider**: GCS, ECS, S3, etc.
2. **Inserisci Credenziali**:
   - **HMAC**: Access Key + Secret Key
   - **Service Account** (solo GCS): Upload JSON o incolla testo
3. **Carica Bucket**: Click su "Lista Bucket" per caricare bucket disponibili
4. **Seleziona Bucket** e opzionalmente un **Path**

#### **2Ô∏è‚É£ Configurazione Destination (Destinazione)**
- **Stessa procedura** del source
- **Pu√≤ essere provider diverso** (es. GCS ‚Üí ECS)

#### **3Ô∏è‚É£ Opzioni Avanzate (Facoltativo)**
Espandi la sezione "‚öôÔ∏è Opzioni Avanzate" per:
- **Dry Run**: Simula sincronizzazione senza trasferire file
- **Verbose**: Log dettagliati
- **Progress**: Mostra progresso trasferimento
- **Fast List**: Ottimizzazione per bucket grandi
- **Custom flags**: Aggiungi flag rclone personalizzati

#### **4Ô∏è‚É£ Avvio Sincronizzazione**
1. **Click "üöÄ Avvia Sincronizzazione"**
2. **Monitoring Real-time**: I log appaiono automaticamente nella console
3. **Completion**: Messaggio di completamento automatico

### **üîê Gestione Credenziali**

#### **HMAC (Standard)**
```
Access Key: AKIA1234567890
Secret Key: wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY
```

#### **GCS Service Account**
- **File Upload**: Drag & drop del file `.json`
- **Text Input**: Copia/incolla del contenuto JSON
- **Project Number**: Inserimento manualenprojectid (required)

---

## üíª Manuale Sviluppatore

### **üèóÔ∏è Architettura**

```mermaid
graph TD
    A[Web UI] --> B[Flask App]
    B --> C[rclone CLI]
    B --> D[Job Manager]
    D --> E[Log Files]
    F[REST API] --> B
    B --> G[SSE Stream]
```

### **üîß Flask Application (`app.py`)**

#### **Core Functions**
- **`list_buckets()`**: Esegue `rclone lsd` per elencare bucket
- **`copy()`**: Lancia `rclone sync` in background con job ID
- **`stream_log()`**: Server-Sent Events per streaming log real-time
- **`jobs()`**: Lista tutti i job attivi/completati

#### **Job Management**
```python
# Job ID formato: YYYYMMDD_HHMMSS_randomstring
job_id = "{}_{}".format(timestamp, uuid.uuid4().hex[:6])

# Log file: /tmp/job_{job_id}.log
log_file = os.path.join(LOG_DIR, "job_{}.log".format(job_id))
```

#### **Environment Handling**
```python
def safe_env():
    """Crea environment isolato per rclone subprocess"""
    env = os.environ.copy()
    # Remove existing rclone env vars
    # Add job-specific credentials
    return env
```

### **‚öôÔ∏è Configuration (`config.py`)**

#### **Provider Definitions**
```python
PROVIDERS = {
    "gcs": "Google Cloud Storage",
    "ecs": "Elastic Cloud Storage",
    "s3": "Amazon S3"
}
```

#### **Flag System**
```python
def get_provider_flags(provider):
    """Ritorna flag specifici per provider"""
    flags = GLOBAL_FLAGS.copy()
    if provider.lower() == 'gcs':
        flags.extend(['--gcs-bucket-policy-only'])
    return flags
```

### **üé® Frontend (`index.html` + `custom.css`)**

#### **Architecture Pattern**
- **Single Page Application** (SPA)
- **Vanilla JavaScript** (no frameworks)
- **Event-driven** UI updates
- **CSS Grid + Flexbox** layout

#### **Key JavaScript Functions**
```javascript
// Provider change handler
function handleProviderChange(type) { /* ... */ }

// Credential validation
function getCredentials(type) { /* ... */ }

// Real-time log streaming
const eventSource = new EventSource('/api/log/' + jobId);
```

---

## üîå API Reference

### **üì° Endpoints**

| Method | Endpoint | Descrizione |
|--------|----------|-------------|
| `POST` | `/api/list_buckets` | Lista bucket di un provider |
| `POST` | `/api/copy` | Avvia job di sincronizzazione |
| `GET` | `/api/log/<job_id>` | Stream real-time log job (SSE) |
| `GET` | `/api/jobs` | Lista tutti i job |

---

### **1Ô∏è‚É£ Lista Bucket**

**Request:**
```bash
curl -X POST http://localhost:8081/api/list_buckets \
  -H "Content-Type: application/json" \
  -d '{
    "provider": "gcs",
    "creds": {
      "sa_credentials": "{\"type\":\"service_account\",\"project_id\":\"my-project\",...}",
      "gcs_project_number": "123456789"
    }
  }'
```

**Response:**
```json
{
  "buckets": [
    "my-production-bucket",
    "my-staging-bucket",
    "my-backup-bucket"
  ]
}
```

---

### **2Ô∏è‚É£ Avvia Sincronizzazione**

**Request:**
```bash
curl -X POST http://localhost:8081/api/copy \
  -H "Content-Type: application/json" \
  -d '{
    "src_provider": "gcs",
    "dst_provider": "ecs",
    "src_bucket": "source-bucket",
    "dst_bucket": "destination-bucket",
    "src_path": "data/2025/",
    "dst_path": "backup/gcs-migration/",
    "src_creds": {
      "auth_method": "sa",
      "sa_credentials": "{...}",
      "gcs_project_number": "123456789"
    },
    "dst_creds": {
      "access_key": "AKIA...",
      "secret_key": "wJal..."
    },
    "additional_flags": ["--verbose", "--progress", "--dry-run"]
  }'
```

**Response:**
```json
{
  "job_id": "20251013_232320_a7f3d2"
}
```

---

### **3Ô∏è‚É£ Monitoring Job**

**Request:**
```bash
curl -N http://localhost:8081/api/log/20251013_232320_a7f3d2
```

**Response (Server-Sent Events):**
```
data: [2025-10-13 23:23:20] Avvio sincronizzazione GCS ‚Üí ECS
data: [2025-10-13 23:23:21] Validazione credenziali GCS...
data: [2025-10-13 23:23:22] Connessione a ECS stabilita
data: [2025-10-13 23:23:23] Scansione source: data/2025/ (1,247 file, 2.3GB)
data: [2025-10-13 23:23:45] Progresso: 45% (1.03GB trasferiti)
data: [2025-10-13 23:24:12] Progresso: 100% (2.3GB trasferiti)
data: [2025-10-13 23:24:13] ‚úÖ Sincronizzazione completata con successo
data: [STREAM_END]
```

---

### **4Ô∏è‚É£ Lista Job**

**Request:**
```bash
curl http://localhost:8081/api/jobs
```

**Response:**
```json
{
  "active_jobs": [
    "20251013_232320_a7f3d2",
    "20251013_231155_b9e4c8",
    "20251013_225430_f1a7d9"
  ],
  "total_jobs": 3
}
```

---

## üìö Use Cases

### **üîÑ Data Migration**

#### **Scenario**: Migrazione da GCS a ECS
```bash
# 1. Verifica bucket source
curl -X POST http://localhost:8081/api/list_buckets \
  -H "Content-Type: application/json" \
  -d '{
    "provider": "gcs",
    "creds": {"sa_credentials": "...", "gcs_project_number": "..."}
  }'

# 2. Dry run per validare
curl -X POST http://localhost:8081/api/copy \
  -H "Content-Type: application/json" \
  -d '{
    "src_provider": "gcs",
    "dst_provider": "ecs",
    "src_bucket": "prod-data-gcs",
    "dst_bucket": "prod-data-ecs",
    "src_creds": {...},
    "dst_creds": {...},
    "additional_flags": ["--dry-run", "--verbose"]
  }'

# 3. Migrazione effettiva
curl -X POST http://localhost:8081/api/copy \
  -H "Content-Type: application/json" \
  -d '{...}' # Senza --dry-run
```

---

### **üìä Backup Automation**

#### **Script Python per Backup Giornaliero**
```python
#!/usr/bin/env python3
import requests
import json
import time
from datetime import datetime

API_BASE = "http://localhost:8081/api"
BACKUP_CONFIG = {
    "src_provider": "s3",
    "dst_provider": "gcs",
    "src_bucket": "production-data",
    "dst_bucket": "daily-backups",
    "dst_path": f"backup/{datetime.now().strftime('%Y-%m-%d')}/",
    "src_creds": {"access_key": "...", "secret_key": "..."},
    "dst_creds": {"sa_credentials": "...", "gcs_project_number": "..."},
    "additional_flags": ["--verbose", "--progress"]
}

def start_backup():
    """Avvia backup giornaliero"""
    response = requests.post(f"{API_BASE}/copy", json=BACKUP_CONFIG)
    job_id = response.json()["job_id"]
    print(f"‚úÖ Backup avviato: {job_id}")
    return job_id

def monitor_job(job_id):
    """Monitora job fino a completamento"""
    with requests.get(f"{API_BASE}/log/{job_id}", stream=True) as r:
        for line in r.iter_lines():
            if line:
                log_line = line.decode('utf-8').replace('data: ', '')
                if log_line == '[STREAM_END]':
                    print("‚úÖ Backup completato!")
                    break
                print(f"üìã {log_line}")

if __name__ == "__main__":
    job_id = start_backup()
    monitor_job(job_id)
```

---

### **üîÑ Multi-Target Sync**

#### **Bash Script per Sync Parallelo**
```bash
#!/bin/bash
# sync-multi-target.sh

API_BASE="http://localhost:8081/api"
SOURCE_CONFIG='{
  "provider": "s3",
  "creds": {"access_key": "...", "secret_key": "..."}
}'

# Configurazioni target
declare -A TARGETS=(
  ["backup-gcs"]='{"provider":"gcs","bucket":"backup-primary"}'
  ["backup-ecs"]='{"provider":"ecs","bucket":"backup-secondary"}'
  ["archive-r2"]='{"provider":"r2","bucket":"archive-longterm"}'
)

declare -a JOB_IDS=()

echo "üöÄ Avvio sincronizzazione multi-target..."

# Avvia job paralleli
for target_name in "${!TARGETS[@]}"; do
  echo "üì° Avvio sync verso: $target_name"

  job_response=$(curl -s -X POST "$API_BASE/copy" \
    -H "Content-Type: application/json" \
    -d '{
      "src_provider": "s3",
      "dst_provider": "gcs",
      "src_bucket": "production-data",
      "dst_bucket": "'$target_name'",
      "src_creds": {"access_key": "...", "secret_key": "..."},
      "dst_creds": {"sa_credentials": "..."},
      "additional_flags": ["--verbose"]
    }')

  job_id=$(echo "$job_response" | jq -r '.job_id')
  JOB_IDS+=("$job_id")
  echo "‚úÖ Job avviato: $job_id"
done

echo "‚è≥ Monitoraggio job paralleli..."
# Qui puoi aggiungere logica di monitoraggio parallelo
```

---

## üîß Troubleshooting

### **‚ùå Errori Comuni**

#### **"rclone: command not found"**
```bash
# Installa rclone
curl https://rclone.org/install.sh | bash

# Verifica PATH
echo $PATH
which rclone
```

#### **"Invalid Service Account JSON"**
```bash
# Valida JSON
cat service-account.json | jq '.'

# Verifica permessi GCS
gcloud auth activate-service-account --key-file=service-account.json
gsutil ls gs://
```

#### **"Job non avviato / Log vuoti"**
```bash
# Verifica permessi directory
ls -la /tmp/
mkdir -p /tmp && chmod 755 /tmp

# Controlla log applicazione
tail -f /tmp/flask_app.log
```

#### **"Bucket non trovati"**
```bash
# Test manuale rclone
rclone lsd gcs: -vv

# Verifica credenziali
rclone config show
```

---

### **üêõ Debug Mode**

#### **Attiva Log Dettagliati**
```bash
# Export log level
export FLASK_ENV=development
export RCLONE_LOG_LEVEL=DEBUG

# Avvia con log verbose
python app.py --debug
```

#### **Test API Endpoints**
```bash
# Health check
curl http://localhost:8081/

# Test job listing
curl http://localhost:8081/api/jobs

# Verifica log specifico
curl http://localhost:8081/api/log/JOB_ID
```

---

### **üîç Log Analysis**

#### **Job Log Location**
```bash
# Directory log
ls -la /tmp/job_*.log

# Real-time monitoring
tail -f /tmp/job_20251013_232320_a7f3d2.log

# Cerca errori
grep -i error /tmp/job_*.log
grep -i "failed\|exception" /tmp/job_*.log
```

#### **Application Log**
```bash
# Flask app log
tail -f /tmp/flask_app.log

# Filtra per livello
grep "ERROR\|CRITICAL" /tmp/flask_app.log
```

---

### **üì¶ Features Richieste**

- [ ] **Docker support** per deployment facile
- [ ] **Authentication** utente con login/logout
- [ ] **Scheduled jobs** con cron integration
- [ ] **Metrics & monitoring** con Prometheus
- [ ] **Multi-language** support (EN/IT)
- [ ] **Backup retention** policies automatiche

---

## üìÑ License

**MIT License** - Vedi [LICENSE](LICENSE) file per dettagli.

---

## üìû Support

- **Issues**: [GitHub Issues](https://github.com/axxx75/s3cp/issues)
- **Documentation**: [Wiki](https://github.com/axxx75/s3cp/wiki)

---

<div align="center">

**Sviluppato con ‚ù§Ô∏è da Axxx e MiniMax Agent**

*Sincronizzazione cloud sicura e affidabile per i tuoi dati*

</div>
